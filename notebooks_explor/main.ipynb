{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ddda124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-audio', created=1756339249, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='gpt-audio-2025-08-28', created=1756256146, object='model', owned_by='system'), Model(id='gpt-realtime', created=1756271701, object='model', owned_by='system'), Model(id='gpt-realtime-2025-08-28', created=1756271773, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'), Model(id='codex-mini-latest', created=1746673257, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system'), Model(id='o4-mini-deep-research', created=1749685485, object='model', owned_by='system'), Model(id='o4-mini-deep-research-2025-06-26', created=1750866121, object='model', owned_by='system'), Model(id='gpt-5-chat-latest', created=1754073306, object='model', owned_by='system'), Model(id='gpt-5-2025-08-07', created=1754075360, object='model', owned_by='system'), Model(id='gpt-5', created=1754425777, object='model', owned_by='system'), Model(id='gpt-5-mini-2025-08-07', created=1754425867, object='model', owned_by='system'), Model(id='gpt-5-mini', created=1754425928, object='model', owned_by='system'), Model(id='gpt-5-nano-2025-08-07', created=1754426303, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')], object='list')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.models.list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bb7fe",
   "metadata": {},
   "source": [
    "## 1 - Prep env + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d050a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import arxiv # pour l’API d’arXiv.org: dépôt d’articles scientifiques\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm working correctly. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=20,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Test\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b54d1a",
   "metadata": {},
   "source": [
    "## 2 -  tools functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b9f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8461a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0915d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7907eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae500a1a",
   "metadata": {},
   "source": [
    "## 3 - Tools Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a27d8f",
   "metadata": {},
   "source": [
    "Schema of each tool which you will provide to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d357be8",
   "metadata": {},
   "source": [
    "The model itself is not going to call these functions.\n",
    "\n",
    "We actually need to write the code to call those functions and pass the data back to the model.\n",
    "\n",
    "But these tools are going to allow the model to extend its functionality.\n",
    "\n",
    "So instead of saying I don't know or hallucinate, we're going to get back the answer that we want here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9870e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630e03d",
   "metadata": {},
   "source": [
    "## 4 - Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c15388",
   "metadata": {},
   "source": [
    "Code handles tool mapping and execution of underlying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ce6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f3f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96e7dd",
   "metadata": {},
   "source": [
    "## 5 - Chatbot Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    # Étape 1 — ENVOYER LA QUESTION AU MODÈLE (avec outils activés)\n",
    "    # 1.1 Préparer l'historique avec le message utilisateur\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    # 1.2 Premier appel au modèle : il peut répondre en texte\n",
    "    #     OU demander d'utiliser un outil (tool_use)\n",
    "    response = client.messages.create(\n",
    "        max_tokens=2024,\n",
    "        model='claude-3-7-sonnet-20250219',\n",
    "        tools=tools,\n",
    "        messages=messages\n",
    "    )\n",
    "    keep_looping = True\n",
    "\n",
    "    # Étape 4 — BOUCLE JUSQU’À LA RÉPONSE FINALE\n",
    "    while keep_looping:\n",
    "        assistant_content = []  # contiendra le texte + éventuels tool_use de CE tour\n",
    "\n",
    "        # Étape 2 — LIRE/INTERPRÉTER LA RÉPONSE DU MODÈLE\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                # 2.1 Cas \"texte direct\" : on affiche le texte\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                # 4.1 Si la réponse ne contient QUE du texte (pas de tool_use),\n",
    "                #     on peut s'arrêter : réponse finale obtenue\n",
    "                if len(response.content) == 1:\n",
    "                    keep_looping = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                # Étape 3 — LE MODÈLE DEMANDE UN OUTIL\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                # 3.1 On enregistre côté assistant ce que le modèle vient de dire\n",
    "                #     (texte éventuel + demande d'outil) dans l'historique\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                # 3.2 Extraire les infos d'appel d'outil\n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                # 3.3 Exécuter l'outil localement et récupérer le résultat\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "\n",
    "                # 3.4 Retourner ce résultat au modèle sous forme de \"tool_result\"\n",
    "                #     (rôle 'user' selon la convention Anthropic)\n",
    "                messages.append({\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_id,\n",
    "                            \"content\": result\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # 3.5 Relancer le modèle avec l'historique mis à jour\n",
    "                response = client.messages.create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc376e1a",
   "metadata": {},
   "source": [
    "## 6 - Chat loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
