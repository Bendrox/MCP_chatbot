{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "171ade34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "from typing import Optional\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, Dict, List, Optional\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "class OpenAI_5_nano():\n",
    "    \"\"\"\n",
    "    Model version : gpt-5-nano-2025-08-07\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI()\n",
    "        self.model= \"gpt-5-nano-2025-08-07\"\n",
    "    \n",
    "    def generate(self, prompt: str, max_tokens: int = 500) -> str:\n",
    "        msg = self.client.responses.create(\n",
    "            model=self.model,\n",
    "            #max_output_tokens=max_tokens,\n",
    "            input=[{\"role\":\"user\", \"content\":prompt }]\n",
    "        )\n",
    "        return msg\n",
    "    \n",
    "    def generate_with_tools(self, messages: List[Dict], max_tokens: int = 256, tools=None):\n",
    "        \"\"\"\n",
    "        Génère une réponse avec support des outils\n",
    "        \"\"\"\n",
    "        msg = self.client.responses.create(\n",
    "            model=self.model,\n",
    "            max_output_tokens=max_tokens,\n",
    "            tools=tools,\n",
    "            input=messages,\n",
    "        )\n",
    "        return msg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a713127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai=OpenAI_5_nano()\n",
    "reponse = openai.generate(\"Hi!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfc6323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you! Here’s a practical overview of what I can do for you.\\n\\nWhat I can help with\\n- Answer questions and explain concepts: science, math, tech, history, language, you name it.\\n- Writing and editing: emails, reports, resumes, essays, blog posts, creative writing. I can adjust tone, style, length, and readability.\\n- Summarizing and translating: condense long texts or translate between many languages.\\n- Problem solving and reasoning: step-by-step explanations for logic, math, puzzles, and decision making.\\n- Coding and technical help: generate code, explain algorithms, debug, review, and offer best practices across languages (Python, JavaScript, Java, C++, etc.).\\n- Data and analytics: interpret data, suggest formulas, create charts or dashboards, and help with spreadsheets (Excel/Sheets).\\n- Planning and productivity: outlines, project plans, study schedules, itineraries, meeting agendas.\\n- Creativity and ideation: brainstorm ideas for products, content, marketing, prompts, and scenes.\\n- Learning and tutoring: practice questions, explanations, flashcards, test prep strategies.\\n- Image understanding: if you share an image, I can describe it, extract visible text, analyze content, and suggest alt text or explanations.\\n\\nImage capabilities\\n- Describe scenes, identify objects, read text visible in images (OCR), and provide quick explanations or summaries.\\n- Helpful for understanding diagrams, graphs, screenshots, and visual prompts.\\n\\nLanguages and accessibility\\n- Multilingual support for many languages.\\n- I can adapt explanations to different reading levels and simplify complex topics.\\n\\nWhat I don’t do (and how I handle it)\\n- I don’t automatically browse the web in real time unless the platform provides browsing tools. I’ll give information up to my knowledge cutoff and can help you verify with external sources.\\n- I don’t access private files or accounts unless you upload or share content here.\\n- I won’t assist with harmful or illegal activities. I’ll steer conversations toward safe, ethical alternatives.\\n\\nGetting started\\n- Tell me your goal or task, share any relevant text or data, and specify any constraints (tone, length, format).\\n- If you have an image, upload it and tell me what you want to learn from it.\\n- I can provide drafts, explanations, code, checklists, or step-by-step solutions—whatever fits your needs.\\n\\nA few quick example prompts\\n- “Explain quantum computing to a beginner in 5 clear steps.”\\n- “Draft a professional cold email to a potential client for our SaaS product.”\\n- “Review this resume and suggest improvements for a software engineer role.”\\n- “I have Python code here. Please debug and optimize it.”\\n- “Summarize this 10-page report into a 1-page executive summary.”\\n- “Describe what’s happening in this image and extract any visible text.”\\n\\nIf you tell me what you’re working on, I can tailor my help right away. What would you like to do first?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reponse.output[1].content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bb7fe",
   "metadata": {},
   "source": [
    "## 1 - Prep env + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d050a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import arxiv # pour l’API d’arXiv.org: dépôt d’articles scientifiques\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011d1943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm working correctly. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=20,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Test\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b54d1a",
   "metadata": {},
   "source": [
    "## 2 -  tools functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b9f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8461a2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1017d094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0915d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1310.7911v2',\n",
       " 'math/9711204v1',\n",
       " '2208.00733v1',\n",
       " '2504.07020v1',\n",
       " '2403.03925v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7907eb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae500a1a",
   "metadata": {},
   "source": [
    "## 3 - Tools Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a27d8f",
   "metadata": {},
   "source": [
    "Schema of each tool which you will provide to the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d357be8",
   "metadata": {},
   "source": [
    "The model itself is not going to call these functions.\n",
    "\n",
    "We actually need to write the code to call those functions and pass the data back to the model.\n",
    "\n",
    "But these tools are going to allow the model to extend its functionality.\n",
    "\n",
    "So instead of saying I don't know or hallucinate, we're going to get back the answer that we want here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9870e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630e03d",
   "metadata": {},
   "source": [
    "## 4 - Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c15388",
   "metadata": {},
   "source": [
    "Code handles tool mapping and execution of underlying functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ce6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f3f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96e7dd",
   "metadata": {},
   "source": [
    "## 5 - Chatbot Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    # Étape 1 — ENVOYER LA QUESTION AU MODÈLE (avec outils activés)\n",
    "    # 1.1 Préparer l'historique avec le message utilisateur\n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    # 1.2 Premier appel au modèle : il peut répondre en texte\n",
    "    #     OU demander d'utiliser un outil (tool_use)\n",
    "    response = client.messages.create(\n",
    "        max_tokens=2024,\n",
    "        model='claude-3-7-sonnet-20250219',\n",
    "        tools=tools,\n",
    "        messages=messages\n",
    "    )\n",
    "    keep_looping = True\n",
    "\n",
    "    # Étape 4 — BOUCLE JUSQU’À LA RÉPONSE FINALE\n",
    "    while keep_looping:\n",
    "        assistant_content = []  # contiendra le texte + éventuels tool_use de CE tour\n",
    "\n",
    "        # Étape 2 — LIRE/INTERPRÉTER LA RÉPONSE DU MODÈLE\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                # 2.1 Cas \"texte direct\" : on affiche le texte\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                # 4.1 Si la réponse ne contient QUE du texte (pas de tool_use),\n",
    "                #     on peut s'arrêter : réponse finale obtenue\n",
    "                if len(response.content) == 1:\n",
    "                    keep_looping = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                # Étape 3 — LE MODÈLE DEMANDE UN OUTIL\n",
    "                assistant_content.append(content)\n",
    "\n",
    "                # 3.1 On enregistre côté assistant ce que le modèle vient de dire\n",
    "                #     (texte éventuel + demande d'outil) dans l'historique\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                # 3.2 Extraire les infos d'appel d'outil\n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                # 3.3 Exécuter l'outil localement et récupérer le résultat\n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "\n",
    "                # 3.4 Retourner ce résultat au modèle sous forme de \"tool_result\"\n",
    "                #     (rôle 'user' selon la convention Anthropic)\n",
    "                messages.append({\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"tool_result\",\n",
    "                            \"tool_use_id\": tool_id,\n",
    "                            \"content\": result\n",
    "                        }\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "                # 3.5 Relancer le modèle avec l'historique mis à jour\n",
    "                response = client.messages.create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc376e1a",
   "metadata": {},
   "source": [
    "## 6 - Chat loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
