{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25968da",
   "metadata": {},
   "source": [
    "## Testing MCP server (local-fake remote) with OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6acd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Statistics ------\n",
      "Input tokens : 159621\n",
      "Output tokens : 3276\n",
      "Total tokens : 162897\n",
      "\n",
      "\n",
      "------------------  Chatbot reponse  ------------------\n",
      "J'ai analysé la structure du dépôt et préparé une proposition de README professionnel en français. Le fichier a été sauvegardé localement dans /workdir_filesystem/README_PROPOSITION.md.\n",
      "\n",
      "Résumé des actions :\n",
      "- Lecture du README existant et du requirements.txt depuis le dépôt GitHub.\n",
      "- Rédaction d'un README professionnel (présentation, structure du dépôt, installation, configuration, exemples d'utilisation, bonnes pratiques, etc.).\n",
      "- Sauvegarde du résultat : /workdir_filesystem/README_PROPOSITION.md\n",
      "\n",
      "Souhaitez-vous :\n",
      "- que je pousse ce README vers le dépôt GitHub (nécessite accès et autorisations) ?\n",
      "- que je modifie des sections (par ex. instructions détaillées pour l'un des chatbots, ajout d'exemples concrets de code, ajout d'une licence) ?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from openai import OpenAI\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client_id_prod=os.getenv('client_id_prod')\n",
    "client_secret_prod=os.getenv('client_secret_prod')\n",
    "\n",
    "\n",
    "def get_token():\n",
    "    token_url = 'https://oauth.piste.gouv.fr/api/oauth/token'\n",
    "    #inject cred \n",
    "    token_data = {\n",
    "    'grant_type': 'client_credentials',\n",
    "    'client_id': client_id_prod,\n",
    "    'client_secret': client_secret_prod,\n",
    "    'scope': 'openid'}\n",
    "    response = requests.post(token_url, data=token_data)\n",
    "    response.raise_for_status()  # vérif  erreurs\n",
    "    # récup  jeton\n",
    "    token_info = response.json()\n",
    "    access_token = token_info['access_token']\n",
    "    return access_token\n",
    "\n",
    "\n",
    "token=get_token()\n",
    "github_barer=os.getenv('github_barer')\n",
    "resp = OpenAI().responses.create(\n",
    "    #model=\"gpt-5-nano-2025-08-07\",\n",
    "    #model='gpt-5-mini-2025-08-07',\n",
    "    model='gpt-5-mini-latest',\n",
    "    tools=[\n",
    "        {\n",
    "            'type': 'mcp',\n",
    "            'server_label': 'fetch',\n",
    "            \"server_url\": \"https://remote.mcpservers.org/fetch/mcp\",\n",
    "            \"require_approval\": \"never\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_label\": \"github\",\n",
    "            \"server_url\": \"https://api.githubcopilot.com/mcp/\",\n",
    "            \"headers\": {\n",
    "                \"Authorization\": f\"Bearer {github_barer}\",  \n",
    "                \"User-Agent\": \"myapp/1.0\",\n",
    "            },\n",
    "            \"require_approval\": \"never\",\n",
    "            \n",
    "        },\n",
    "        {\n",
    "            'type': 'mcp',\n",
    "            'server_label': 'OB_remote_server',\n",
    "            \"server_url\": \"https://50d2463a7f5c.ngrok-free.app/sse\",\n",
    "            \"require_approval\": \"never\"\n",
    "        }\n",
    "        ],\n",
    "input=\"clone ce repos https://github.com/Bendrox/MCP_chatbot.git et fait moi une proposition de fichier README professionel en analysant les fichiers et la structure du projet et sauvgarde le résultat\"\n",
    "#input=\"Sans appeler d'outil, dresse un inventaire des outils MCP que tu vois\"\n",
    "#input=f\"récupère et compare les versions précédente et en vigueur du texte LEGIARTI000041577698 et trouve moi le numéro celex de la directive a l origine de la modification tu pourras utiliser le token suivant {token}  pour récupérer les infos \"\n",
    ")\n",
    "\n",
    "print(\"------ Statistics ------\")\n",
    "print(f\"Input tokens : {resp.usage.input_tokens}\" )\n",
    "print(f\"Output tokens : {resp.usage.output_tokens}\" )\n",
    "#print(f\"cached_tokens : {resp.usage.input_tokens_details.cached_tokens}\")\n",
    "print(f\"Total tokens : {resp.usage.total_tokens}\" )\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"------------------  Chatbot reponse  ------------------\")\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_env_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
